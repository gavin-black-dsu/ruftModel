{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9257c2f5-d58b-45cd-9d66-91ea44fe1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427ad300-eb4a-434e-bd00-a0c8669f4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ProgressBar\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ae517-2c1e-41bd-96b2-a342492fb3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24cbe66e-331b-46a6-8fc8-c6a20277abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium') # Or 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b44c4fc-cdc0-4c5b-ad66-f0d37b3ce2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = type('Args', (object,), {})\n",
    "args = Args()\n",
    "\n",
    "args.file = \"data/synthetic_data.csv\"\n",
    "args.inputs = 357\n",
    "args.outputs = 1\n",
    "args.patience = 5\n",
    "args.min_delta = 0.001\n",
    "args.val_size = 0.2\n",
    "args.batch_size = 128\n",
    "args.max_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7cd00b7-9be3-459d-9e86-06cd3f438597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuftModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, hidden_size=128, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU() \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        #self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        #x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch  \n",
    "        y_hat = self(x)\n",
    "        loss = nn.BCEWithLogitsLoss()(y_hat.view(-1), y.type_as(y_hat).view(-1))  # Adjusting shapes\n",
    "        self.log('loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.training_step(batch, batch_idx)\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = nn.BCEWithLogitsLoss()(y_hat.view(-1), y.type_as(y_hat).view(-1))\n",
    "        self.log('val_loss', val_loss)\n",
    "        \n",
    "        return val_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c260b02-88bd-488d-b101-79ed93ff75b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProgressBar(ProgressBar):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.training_loss = []\n",
    "        self.validation_loss = []\n",
    "    \n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        super().on_train_batch_end(trainer, pl_module, outputs, batch, batch_idx)\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        pass\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        loss_txt = \"N/A\"\n",
    "        val_loss_txt = \"N/A\"\n",
    "        loss = trainer.logged_metrics.get('loss')\n",
    "        val_loss = trainer.logged_metrics.get('val_loss')\n",
    "        \n",
    "        if loss is not None: \n",
    "            loss_txt = f\"{loss:.4f}\"\n",
    "            self.training_loss.append(loss.cpu())\n",
    "            \n",
    "        if val_loss is not None: \n",
    "            val_loss_txt = f\"{val_loss:.4f}\"\n",
    "            self.validation_loss.append(val_loss.cpu())    \n",
    "        \n",
    "        print(f'Epoch {trainer.current_epoch + 1}: loss / val_loss = {loss_txt} / {val_loss_txt}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f54b0d-ad47-427d-8bd0-4ae166f67ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features, dtype=torch.float)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1114b943-953f-47f7-a1d7-05d43f40d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=args.min_delta,\n",
    "    patience=args.patience,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "323a9850-2d9d-4250-acf0-cb7edd42c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/libxml2_train.pkl')  \n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1:].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=args.val_size)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f5bd138-1e24-44a1-9c17-efcdef0e9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ResourceDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=10, shuffle=True)\n",
    "val_dataset = ResourceDataset(X_val, y_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839b90d1-2bc7-4f78-b249-e011cbf53b17",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-11-17 12:56:44.569371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 12:56:44.569397: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 12:56:44.569411: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    }
   ],
   "source": [
    "model = RuftModel(args.inputs, args.outputs)\n",
    "\n",
    "progress_bar = CustomProgressBar()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stop_callback, progress_bar],\n",
    "    logger=True\n",
    ")\n",
    "\n",
    "startLoss = trainer.test(model, train_dataloader, verbose=False)[0]['loss']\n",
    "progress_bar.training_loss.append(startLoss) # Seed the metrics with the initial loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a40714d-c708-43ec-8dd2-40984f60b60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | layer   | Linear  | 45.8 K\n",
      "1 | hidden  | Linear  | 16.5 K\n",
      "2 | output  | Linear  | 129   \n",
      "3 | relu    | ReLU    | 0     \n",
      "4 | dropout | Dropout | 0     \n",
      "------------------------------------\n",
      "62.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.5 K    Total params\n",
      "0.250     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss / val_loss = N/A / 0.6973\n",
      "Epoch 1: loss / val_loss = 0.0001 / 0.0070\n",
      "Epoch 2: loss / val_loss = 0.0011 / 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6603042-d2ad-4f2c-b5a9-0f31128deb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_for_explanation = next(iter(val_dataloader))\n",
    "features, _ = data_for_explanation\n",
    "\n",
    "explainer = shap.GradientExplainer(model, features)\n",
    "shap_values = explainer.shap_values(features)\n",
    "shap.summary_plot(shap_values, features, feature_names=list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a35c73-a1a5-4f57-bd7c-1c4f05f03cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(progress_bar.training_loss, label='Training Loss')\n",
    "plt.plot(progress_bar.validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc15e66f-8aee-4517-b4dd-da9518ce9176",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "train_dataloader.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93754b7-5072-4adf-afa4-c4dc753e30c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amira",
   "language": "python",
   "name": "amira"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
