{
 "cells": [
  {
   "cell_type": "raw",
   "id": "98fad05e-b80f-4a41-82e7-28f61712e3ed",
   "metadata": {},
   "source": [
    "Losses:\n",
    "  Continuous: MSLE\n",
    "  Binary: BCE\n",
    "  Sequence: CE\n",
    "  \n",
    "LR_Scheduler: LambdaLR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9257c2f5-d58b-45cd-9d66-91ea44fe1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427ad300-eb4a-434e-bd00-a0c8669f4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ProgressBar\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pacmap\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24cbe66e-331b-46a6-8fc8-c6a20277abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium') # Or 'high'\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b44c4fc-cdc0-4c5b-ad66-f0d37b3ce2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = type('Args', (object,), {})\n",
    "args = Args()\n",
    "\n",
    "args.file = 'data/libxml2_train.pkl'\n",
    "args.inputs = 257\n",
    "args.outputs = 1\n",
    "args.patience = 5\n",
    "args.min_delta = 0.001\n",
    "args.val_size = 0.2\n",
    "args.batch_size = 128\n",
    "args.max_epochs = 5000\n",
    "args.pacmap_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c83753-c771-40db-a004-5b17688c7510",
   "metadata": {},
   "source": [
    "# Base Model and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7cd00b7-9be3-459d-9e86-06cd3f438597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuftModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, hidden_size=128, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU() \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        #self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        #x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch  \n",
    "        y_hat = self(x)\n",
    "        loss = nn.BCEWithLogitsLoss()(y_hat.view(-1), y.type_as(y_hat).view(-1))  # Adjusting shapes\n",
    "        self.log('loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.training_step(batch, batch_idx)\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = nn.BCEWithLogitsLoss()(y_hat.view(-1), y.type_as(y_hat).view(-1))\n",
    "        self.log('val_loss', val_loss)\n",
    "        \n",
    "        return val_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c260b02-88bd-488d-b101-79ed93ff75b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProgressBar(ProgressBar):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.training_loss = []\n",
    "        self.validation_loss = []\n",
    "    \n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        super().on_train_batch_end(trainer, pl_module, outputs, batch, batch_idx)\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        pass\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        loss_txt = \"N/A\"\n",
    "        val_loss_txt = \"N/A\"\n",
    "        loss = trainer.logged_metrics.get('loss')\n",
    "        val_loss = trainer.logged_metrics.get('val_loss')\n",
    "        \n",
    "        if loss is not None: \n",
    "            loss_txt = f\"{loss:.4f}\"\n",
    "            self.training_loss.append(loss.cpu())\n",
    "            \n",
    "        if val_loss is not None: \n",
    "            val_loss_txt = f\"{val_loss:.4f}\"\n",
    "            self.validation_loss.append(val_loss.cpu())    \n",
    "        \n",
    "        print(f'Epoch {trainer.current_epoch + 1}: loss / val_loss = {loss_txt} / {val_loss_txt}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f54b0d-ad47-427d-8bd0-4ae166f67ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features, dtype=torch.float)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d57e996-3799-4a12-8bb4-ec64b339ac17",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "323a9850-2d9d-4250-acf0-cb7edd42c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(args.file)  \n",
    "data = data.sample(frac=1) # Make sure we've sorted\n",
    "samples = data.iloc[:,-2:-1]\n",
    "X = data.iloc[:, :-2].values # -1 skip label\n",
    "y = data.iloc[:, -1:].values # -1 only 1 label\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=args.val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5bd138-1e24-44a1-9c17-efcdef0e9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ResourceDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=10, shuffle=True)\n",
    "val_dataset = ResourceDataset(X_val, y_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6dc69e-b3ba-424b-838c-df8259d59a54",
   "metadata": {},
   "source": [
    "# Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2034e2d0-adc1-4ecd-9197-97a85d886a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0) \n",
    "X_transformed = embedding.fit_transform(X_val[:args.pacmap_samples], init=\"pca\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f026e7-71e0-4f50-bb7e-90d9b78e01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must convert to string or plotly will complain about bytes\n",
    "sample_text = []\n",
    "for s in data['sample'][:args.pacmap_samples]: sample_text.append([str(s)])\n",
    "\n",
    "\n",
    "plotly_rows = np.hstack([X_transformed, y_val[:args.pacmap_samples], sample_text])\n",
    "plotly_df = pd.DataFrame( plotly_rows, columns=[\"X\", \"Y\", \"Label\", \"Sample\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c8975c2-7500-4825-b330-1da16ba30496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the proper types in the dataframe\n",
    "convert_dict = {'X': float,\n",
    "                'Y': float,\n",
    "                'Label': float\n",
    "                }\n",
    " \n",
    "plotly_df = plotly_df.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8bf9f0-d650-484e-a510-673ee33770f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_13.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter( plotly_df, x='X' , y='Y', color='Label', custom_data=['Sample'], \n",
    "                  title=\"Initial Dataset PaCMAP\", width=800, height=800, template = 'plotly_dark')\n",
    "fig.update_traces(hovertemplate =  \"%{customdata[0]}\")\n",
    "fig.update_xaxes(showticklabels=False) \n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e572a-b6cf-4f6d-9c95-0941af20bed5",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1114b943-953f-47f7-a1d7-05d43f40d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=args.min_delta,\n",
    "    patience=args.patience,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "839b90d1-2bc7-4f78-b249-e011cbf53b17",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RuftModel(args.inputs, args.outputs)\n",
    "\n",
    "torch.onnx.export(model,torch.tensor(X_train[0], dtype=torch.float),\"test.onnx\") #, batch.text, 'rnn.onnx', input_names=input_names, output_names=output_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819e37b-1dec-4ba0-a0c8-011219b0e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = CustomProgressBar()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stop_callback, progress_bar],\n",
    "    logger=True\n",
    ")\n",
    "\n",
    "startLoss = trainer.test(model, train_dataloader, verbose=False)[0]['loss']\n",
    "progress_bar.training_loss.append(startLoss) # Seed the metrics with the initial loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40714d-c708-43ec-8dd2-40984f60b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120321e5-5c5e-4618-902d-63098b3c62e0",
   "metadata": {},
   "source": [
    "# SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6603042-d2ad-4f2c-b5a9-0f31128deb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_explanation = next(iter(val_dataloader))\n",
    "features, _ = data_for_explanation\n",
    "\n",
    "explainer = shap.GradientExplainer(model, features)\n",
    "shap_values = explainer.shap_values(features)\n",
    "shap.summary_plot(shap_values, features, feature_names=list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf62c51-3312-4e20-9ee3-7bf05975afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer(features)[24]\n",
    "exp.base_values = 0.5\n",
    "exp.feature_names = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7a85d-9887-4420-92e1-dbb563903cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.waterfall_plot(exp, max_display=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a35c73-a1a5-4f57-bd7c-1c4f05f03cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(progress_bar.training_loss, label='Training Loss', zorder=1)\n",
    "#plt.plot(progress_bar.validation_loss, label='Validation Loss', linestyle=(0, (1, 10)))\n",
    "plt.scatter( range(len(progress_bar.validation_loss)), progress_bar.validation_loss, \n",
    "             s=50, alpha=0.5, c='orange', zorder=2)\n",
    "plt.plot(progress_bar.validation_loss, label='Validation Loss', c='orange', linestyle='dashed', alpha=0.25)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amira",
   "language": "python",
   "name": "amira"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
