{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a5fca-a082-41c2-81b1-752528bfc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pacmap import PaCMAP\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e77262-0fbf-41b1-b791-21a2f0ba8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "PACMAP_SIZE = 10000 # Number of samples to use for PaCMAP\n",
    "NUM_TARGETS = 1 # Number of resource features (y)\n",
    "TRAIN_SPLIT = 0.8\n",
    "BATCH_SIZE=1024\n",
    "EPOCHS=10\n",
    "FILE=\"data/libxml2_byteArrays.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442effa-5e43-42b3-b1ef-44ee85ac1a13",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5bd360-1998-481f-acd2-e70972731326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_layers, num_outputs):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embed = nn.Embedding(input_dim, input_dim)\n",
    "        transformer_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(input_dim, num_outputs)\n",
    "\n",
    "    def pooling(self, x):\n",
    "        x = self.embed(x)  # Embedding input\n",
    "        x = x.permute(1, 0, 2)  # Reshape for transformer\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)  # Pooling\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pooling(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ByteSequenceModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(ByteSequenceModel, self).__init__()\n",
    "        self.model = TransformerModel(input_dim=256, num_heads=8, num_layers=4, num_outputs=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72d3dc-1dda-4a92-be97-03b7f6328bc9",
   "metadata": {},
   "source": [
    "# Data loading definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc92475-f4d5-4ee5-8c8e-f1d2aad108b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ByteSequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb315c-26e0-4851-ad6a-a7232c81f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ByteSequenceDataModule(LightningModule):\n",
    "    def __init__(self, train_dataset, val_dataset, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fba087-fd61-4b0e-89c1-c128b3cb42c3",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114cf3f4-0f17-4753-96bf-1d9e25cffaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, 'rb') as file:\n",
    "    byte_sequences, labels = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e2dcb-abca-4f7d-af24-e288943b3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sequences = [[int(b) for b in byte_seq]  + [0] * (150 - len(byte_seq)) for byte_seq in byte_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf523c2-8609-4094-a867-d619288d8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sequences_tensor = torch.LongTensor(int_sequences)\n",
    "labels_tensor = torch.FloatTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586fb92-0f35-40a2-bf2a-a0c1f8a15d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ByteSequenceDataset(int_sequences_tensor, labels_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48bc50e-79ab-4cea-bfc9-1455ad6e6220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train_size = int(TRAIN_SPLIT * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f5b36-23fe-472d-b8bc-a89124e1d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ByteSequenceDataModule(train_dataset, val_dataset, batch_size=BATCH_SIZE)\n",
    "model = ByteSequenceModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165d19d-9dd4-4878-9beb-787b4e186f41",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472fb07-8690-45b2-927e-c42f686e3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=EPOCHS) \n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a118eaf-7315-4588-9d49-2f592cec9dca",
   "metadata": {},
   "source": [
    "# View contextual layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66d8ea-a9a4-4f26-9f61-49322d88d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x, _ = batch\n",
    "            context = model.model.pooling(x)\n",
    "            embeddings.append(context)\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "val_loader = DataLoader(Subset(val_dataset, range(0,PACMAP_SIZE)), batch_size=BATCH_SIZE)\n",
    "embeddings = get_embeddings(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b13b9c-a3a1-4242-8e60-57445cdd17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pacmap_instance = PaCMAP(n_components=2, n_neighbors=10, MN_ratio=0.5, FP_ratio=2.0)\n",
    "reduced_embeddings = pacmap_instance.fit_transform(embeddings.cpu().numpy())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], alpha=0.7)\n",
    "plt.title(\"PaCMAP Visualization of Contextual Embeddings\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934ebda-71fe-4402-827f-6cc4b7d39fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amira",
   "language": "python",
   "name": "amira"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
