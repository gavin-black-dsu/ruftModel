{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9f5ab1f8-023a-4a06-8f1a-0a68722d2bce",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "Identifying Useful Features for Malware Detection in the Ember Dataset \\cite{8951564} \n",
    " - Entropy\n",
    " - Byte Histogram (Counts)\n",
    "\n",
    "Integrated Static and Dynamic Analysis for Malware Detection \\cite{SHIJO2015804}\n",
    " - String presence\n",
    " - n-gram frequencies\n",
    "\n",
    "Malware Detection in Android via Neural Network using Entropy Features \\cite{9701413}\n",
    " - Sliding window entropy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413d9f5d-7dc2-4668-ad14-f5be6b90d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6b60a6-b3aa-49f6-9582-64326cb1afa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_entropy(byte_array):\n",
    "    counts = [0] * 256\n",
    "    for byte in byte_array:\n",
    "        counts[byte] += 1\n",
    "    counts = np.array(counts)\n",
    "    ent = entropy(counts, base=2)\n",
    "    \n",
    "    return (ent, counts )\n",
    "\n",
    "print(get_entropy(b\"y\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812e1432-666b-4765-b538-131b5291f744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foobar', 'test']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_substrings(s, min_length, max_length):\n",
    "    \"\"\"Generate substrings of a given string within a specified length range.\"\"\"\n",
    "    length = len(s)\n",
    "    return [s[i:j] for i in range(length) for j in range(i + min_length, min(i + max_length + 1, length + 1))]\n",
    "\n",
    "def most_common_substrings(strings, min_substring_length=4, max_substring_length=10, min_occurrences=3):\n",
    "    \"\"\"Return the most common substrings sorted by frequency and alphabetically, \n",
    "    excluding those that are substrings of other returned values.\"\"\"\n",
    "    substrings = []\n",
    "    for string in strings:\n",
    "        substrings.extend(get_substrings(string, min_substring_length, max_substring_length))\n",
    "\n",
    "    # Count the frequency of each substring\n",
    "    substring_count = Counter(substrings)\n",
    "\n",
    "    # Filter substrings based on minimum occurrence threshold\n",
    "    filtered_substrings = {substring: count for substring, count in substring_count.items() if count >= min_occurrences}\n",
    "\n",
    "    # Sort by frequency (descending) and alphabetically\n",
    "    sorted_substrings = sorted(filtered_substrings, key=lambda x: (-filtered_substrings[x], x))\n",
    "\n",
    "    # Remove substrings that are part of longer substrings in the list\n",
    "    final_substrings = []\n",
    "    for substring in sorted_substrings:\n",
    "        if not any(substring in other and substring != other for other in sorted_substrings):\n",
    "            final_substrings.append(substring)\n",
    "\n",
    "    return final_substrings\n",
    "\n",
    "\n",
    "# Example usage\n",
    "strings = [\"testing\", \"this is a test\", \"foobar\", \"fazbar\", \"what is foobar\", \"can afoobart the testers\"]\n",
    "print(most_common_substrings(strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c029f8-0c97-4ae6-838a-92b7c7b17b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yth', 'f p', 'n p', 'ell', 'rog', 'ing', ' wo', 'pyt', 'd o', 'llo', ' of', 'on ', 'pro', 'lo ', 'rld', 'amm', 'o w', 'wor', 'of ', 'ogr', 'ram', ' py', 'mmi', 'tho', 'ld ', 'hon', 'min', 'hel', 'orl', ' pr', 'gra']\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "N-gram at index 0: ell\n",
      "N-gram at index 0: llo\n",
      "N-gram at index 0: lo \n",
      "N-gram at index 0: hel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_unique_ngrams_set(strings, n):\n",
    "    def generate_ngrams(s):\n",
    "        return [s[i:i + n] for i in range(len(s) - n + 1)]\n",
    "\n",
    "    all_ngrams = set()\n",
    "    for s in strings:\n",
    "        ngrams = generate_ngrams(s)\n",
    "        all_ngrams.update(ngrams)\n",
    "    return list(all_ngrams)  # Convert to list to maintain order\n",
    "\n",
    "def count_ngrams_in_string(s, ngrams, n):\n",
    "    ngram_counts = Counter(s[i:i + n] for i in range(len(s) - n + 1))\n",
    "    return [ngram_counts[ngram] for ngram in ngrams]\n",
    "\n",
    "def get_ngram_by_index(ngrams, index):\n",
    "    if 0 <= index < len(ngrams):\n",
    "        return ngrams[index]\n",
    "    else:\n",
    "        return \"Index out of range\"\n",
    "\n",
    "# Example usage\n",
    "n = 4\n",
    "strings = [\"hello world\", \"world of python\", \"python programming\"]\n",
    "unique_ngrams = create_unique_ngrams_set(strings, n)\n",
    "print(unique_ngrams)\n",
    "\n",
    "test_string = \"hello \"\n",
    "ngram_counts = count_ngrams_in_string(test_string, unique_ngrams, n)\n",
    "print(ngram_counts)\n",
    "\n",
    "# Get the n-gram at a specific index\n",
    "for i, x in enumerate(ngram_counts):\n",
    "    if x > 0: \n",
    "        ngram_at_index = get_ngram_by_index(unique_ngrams, i)\n",
    "        print(f\"N-gram at index {index}: {ngram_at_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d89411-852f-4cd1-8d5a-f0186d1f9fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amira",
   "language": "python",
   "name": "amira"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
